{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18ce1a6",
   "metadata": {},
   "source": [
    "# 4 or more ML Classifiers - Submission\n",
    "\n",
    "Will basically copy over first_model notebook things, and then make new models sections. Thinking of doing Logistic Regression, XGBoost, and SVM. Open to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7f875",
   "metadata": {},
   "source": [
    "<h3>Setup and Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff794371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully!\n",
      "âœ“ Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")\n",
    "print(f\"âœ“ Random seed set to: 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c3832",
   "metadata": {},
   "source": [
    "<h1>Load Preprocessed Data</h1>\n",
    "<b>Load data and perform embedded vector conversion from string to numerical</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b450f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (89302, 109)\n",
      "Total samples: 89,302\n",
      "Total features (including target): 109\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>DLC count</th>\n",
       "      <th>About the game</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Mac</th>\n",
       "      <th>Linux</th>\n",
       "      <th>Achievements</th>\n",
       "      <th>Release_Year</th>\n",
       "      <th>Release_Month</th>\n",
       "      <th>Release_Day</th>\n",
       "      <th>...</th>\n",
       "      <th>Publishers_LTD</th>\n",
       "      <th>Publishers_EroticGamesClub</th>\n",
       "      <th>Publishers_Square_Enix</th>\n",
       "      <th>Publishers_Strategy_First</th>\n",
       "      <th>Publishers_HH_Games</th>\n",
       "      <th>Publishers_Choice_of_Games</th>\n",
       "      <th>Publishers_Sekai_Project</th>\n",
       "      <th>Publishers_Electronic_Arts</th>\n",
       "      <th>Publishers_Atomic_Fabrik</th>\n",
       "      <th>popularity_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.007898</td>\n",
       "      <td>-0.039159</td>\n",
       "      <td>[ 2.43655536e-02 -4.33482192e-02 -1.89679326e-...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.057969</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.963858</td>\n",
       "      <td>-0.039159</td>\n",
       "      <td>[-1.18375435e-01  6.85120896e-02 -8.45908746e-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.049630</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.338225</td>\n",
       "      <td>-0.039159</td>\n",
       "      <td>[-7.47546032e-02 -1.29440166e-02  2.83202082e-...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.121362</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.181817</td>\n",
       "      <td>-0.039159</td>\n",
       "      <td>[ 2.98691001e-02  1.47273587e-02  5.98186301e-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.121362</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.118702</td>\n",
       "      <td>-0.039159</td>\n",
       "      <td>[-6.26481697e-02  7.47049646e-03 -5.16111143e-...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.019741</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  DLC count                                     About the game  \\\n",
       "0  2.007898  -0.039159  [ 2.43655536e-02 -4.33482192e-02 -1.89679326e-...   \n",
       "1 -0.963858  -0.039159  [-1.18375435e-01  6.85120896e-02 -8.45908746e-...   \n",
       "2 -0.338225  -0.039159  [-7.47546032e-02 -1.29440166e-02  2.83202082e-...   \n",
       "3 -0.181817  -0.039159  [ 2.98691001e-02  1.47273587e-02  5.98186301e-...   \n",
       "4 -1.118702  -0.039159  [-6.26481697e-02  7.47049646e-03 -5.16111143e-...   \n",
       "\n",
       "   Windows    Mac  Linux  Achievements  Release_Year  Release_Month  \\\n",
       "0     True  False  False      0.057969          2008             10   \n",
       "1     True   True  False     -0.049630          2017             10   \n",
       "2     True  False  False     -0.121362          2021             11   \n",
       "3     True   True   True     -0.121362          2020              7   \n",
       "4     True   True  False     -0.019741          2020              2   \n",
       "\n",
       "   Release_Day  ...  Publishers_LTD  Publishers_EroticGamesClub  \\\n",
       "0           21  ...               0                           0   \n",
       "1           12  ...               0                           0   \n",
       "2           17  ...               0                           0   \n",
       "3           23  ...               0                           0   \n",
       "4            3  ...               0                           0   \n",
       "\n",
       "   Publishers_Square_Enix  Publishers_Strategy_First  Publishers_HH_Games  \\\n",
       "0                       0                          0                    0   \n",
       "1                       0                          0                    0   \n",
       "2                       0                          0                    0   \n",
       "3                       0                          0                    0   \n",
       "4                       0                          0                    0   \n",
       "\n",
       "   Publishers_Choice_of_Games  Publishers_Sekai_Project  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   Publishers_Electronic_Arts  Publishers_Atomic_Fabrik  popularity_class  \n",
       "0                           0                         0               Low  \n",
       "1                           0                         0               Low  \n",
       "2                           0                         0               Low  \n",
       "3                           0                         0               Low  \n",
       "4                           0                         0               Low  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed dataset with NLP embeddings\n",
    "df = pd.read_csv('data/processed/games_preprocessed.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Total samples: {df.shape[0]:,}\")\n",
    "print(f\"Total features (including target): {df.shape[1]}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19759fc",
   "metadata": {},
   "source": [
    "<b>Conversion from string embedded vectors to numeric embedded vectors</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb2415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 'About the game' embeddings from strings to numeric arrays...\n",
      "âœ“ Conversion complete!\n",
      "âœ“ Sample embedding shape: (384,)\n",
      "âœ“ Sample embedding (first 10 values): [ 0.02436555 -0.04334822 -0.00189679 -0.03764986 -0.08963642  0.02961544\n",
      " -0.0579943   0.0187653   0.01877719  0.06303879]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Check if 'About the game' column exists and contains string representations of arrays\n",
    "if 'About the game' in df.columns:\n",
    "    print(\"Converting 'About the game' embeddings from strings to numeric arrays...\")\n",
    "    \n",
    "    # Convert string representations to actual arrays\n",
    "    def string_to_array(s):\n",
    "        if isinstance(s, str):\n",
    "            # Remove extra whitespace and convert to numpy array\n",
    "            return np.fromstring(s.strip('[]'), sep=' ')\n",
    "        return s\n",
    "    \n",
    "    df['About the game'] = df['About the game'].apply(string_to_array)\n",
    "    \n",
    "    print(f\"âœ“ Conversion complete!\")\n",
    "    print(f\"âœ“ Sample embedding shape: {df['About the game'].iloc[0].shape}\")\n",
    "    print(f\"âœ“ Sample embedding (first 10 values): {df['About the game'].iloc[0][:10]}\")\n",
    "else:\n",
    "    print(\"'About the game' column not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f867f",
   "metadata": {},
   "source": [
    "<b>Place numeric embedded vectors back into the 'About the game' column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716ddf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding embeddings into separate columns...\n",
      "âœ“ Expanded embeddings into 384 numeric columns\n",
      "âœ“ New dataset shape: (89302, 492)\n",
      "âœ“ First few column names: ['embedding_0', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4']\n",
      "âœ“ Last few column names: ['Publishers_Choice_of_Games', 'Publishers_Sekai_Project', 'Publishers_Electronic_Arts', 'Publishers_Atomic_Fabrik', 'popularity_class']\n"
     ]
    }
   ],
   "source": [
    "# Expand embeddings into separate columns\n",
    "# This is necessary because sklearn models need 2D numeric arrays, not arrays within cells\n",
    "\n",
    "if 'About the game' in df.columns:\n",
    "    print(\"Expanding embeddings into separate columns...\")\n",
    "    \n",
    "    # Convert the 'About the game' column (which contains arrays) into separate columns\n",
    "    embeddings_list = df['About the game'].tolist()\n",
    "    embeddings_df = pd.DataFrame(embeddings_list, \n",
    "                                  columns=[f'embedding_{i}' for i in range(len(embeddings_list[0]))])\n",
    "    \n",
    "    # Drop the original 'About the game' column\n",
    "    df = df.drop('About the game', axis=1)\n",
    "    \n",
    "    # Insert embedding columns at the beginning\n",
    "    df = pd.concat([embeddings_df, df], axis=1)\n",
    "    \n",
    "    print(f\"âœ“ Expanded embeddings into {len(embeddings_list[0])} numeric columns\")\n",
    "    print(f\"âœ“ New dataset shape: {df.shape}\")\n",
    "    print(f\"âœ“ First few column names: {df.columns[:5].tolist()}\")\n",
    "    print(f\"âœ“ Last few column names: {df.columns[-5:].tolist()}\")\n",
    "else:\n",
    "    print(\"No embedding expansion needed - 'About the game' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a99e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution:\n",
      "popularity_class\n",
      "Low       78429\n",
      "Medium     8934\n",
      "High       1939\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "popularity_class\n",
      "Low       87.824461\n",
      "Medium    10.004255\n",
      "High       2.171284\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check target variable distribution\n",
    "print(\"Target variable distribution:\")\n",
    "print(df['popularity_class'].value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(df['popularity_class'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb33d2",
   "metadata": {},
   "source": [
    "<h1>Prepared Raw and Processed Data for Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1449e43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (89302, 491)\n",
      "Target (y) shape: (89302,)\n",
      "\n",
      "Total number of features: 491\n",
      "\n",
      "Feature data types:\n",
      "float64    387\n",
      "int64      101\n",
      "bool         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('popularity_class', axis=1)\n",
    "y = df['popularity_class']\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"\\nTotal number of features: {X.shape[1]}\")\n",
    "print(f\"\\nFeature data types:\")\n",
    "print(X.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91ebc8",
   "metadata": {},
   "source": [
    "<b>Ensure all data is in some numeric form</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1cc152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for non-numeric columns...\n",
      "\n",
      "Data types in features:\n",
      "float64    387\n",
      "int64      101\n",
      "bool         3\n",
      "Name: count, dtype: int64\n",
      "âœ“ All columns are numeric!\n",
      "\n",
      "Final feature set shape: (89302, 491)\n",
      "Final feature types:\n",
      "float64    387\n",
      "int64      101\n",
      "bool         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric columns in X\n",
    "print(\"Checking for non-numeric columns...\")\n",
    "print(f\"\\nData types in features:\")\n",
    "print(X.dtypes.value_counts())\n",
    "\n",
    "# Identify object (string) columns\n",
    "object_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if object_cols:\n",
    "    print(f\"\\nâš  Found {len(object_cols)} non-numeric columns:\")\n",
    "    for col in object_cols:\n",
    "        print(f\"  - {col}: {X[col].nunique()} unique values\")\n",
    "        print(f\"    Sample values: {X[col].dropna().head(3).tolist()}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Dropping non-numeric columns: {object_cols}\")\n",
    "    X = X.drop(columns=object_cols)\n",
    "    print(f\"âœ“ Remaining features: {X.shape[1]}\")\n",
    "else:\n",
    "    print(\"âœ“ All columns are numeric!\")\n",
    "\n",
    "print(f\"\\nFinal feature set shape: {X.shape}\")\n",
    "print(f\"Final feature types:\\n{X.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93235bd4",
   "metadata": {},
   "source": [
    "<b>Split data into training and test sets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956d6513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 71441 samples\n",
      "Testing set size: 17861 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets (80/20 split)\n",
    "# Use stratify to maintain class distribution in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f9bd3",
   "metadata": {},
   "source": [
    "<h1>Re-perform Split Again after using SelectKBest to Find 20 Best Features</h1>\n",
    "<b>Perform SelectKBest on the data with ANOVA F-statistic</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1adee439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features before SelectKBest with ANOVA:  (89302, 491)\n",
      "Features after SelectKBest with ANOVA:   (89302, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features before SelectKBest with ANOVA: \", X.shape)\n",
    "X_new = SelectKBest(f_classif, k=20).fit_transform(X, y)\n",
    "\n",
    "print(\"Features after SelectKBest with ANOVA:  \", X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39df02",
   "metadata": {},
   "source": [
    "<b>Recreate test split in X_newTrain, X_NewTest, Y_NewTrain, Y_NewTest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f2d13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 71441 samples\n",
      "Testing set size: 17861 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets (80/20 split)\n",
    "# Use stratify to maintain class distribution in both sets\n",
    "X_NewTrain, X_NewTest, y_NewTrain, y_NewTest = train_test_split(\n",
    "    X_new, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41692199",
   "metadata": {},
   "source": [
    "<h1>Model 1-1: Random Forest with Full Feature Set</h1>\n",
    "  \n",
    "<b>Define and Fit the Model for Learning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4900cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1 with full feature set...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier for Model 1 (Full Feature Set)\n",
    "model_M1 = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Model 1 with full feature set...\")\n",
    "# Fit the model on training set\n",
    "model_M1.fit(X_train, y_train)\n",
    "print(\"âœ“ Model 1 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9344c42",
   "metadata": {},
   "source": [
    "<b>Save Fitted Model to Disk and Evaluate Model's Performance with accuracy and F1-Score</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863235ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model 1 to disk\n",
    "import sklearn\n",
    "filename_M1 = 'finalized_model_M1-1.sav'\n",
    "pickle.dump(model_M1, open(filename_M1, 'wb'))\n",
    "print(f\"âœ“ Model 1 saved as: {filename_M1}\")\n",
    "\n",
    "# Load the model from disk to verify\n",
    "loaded_model_M1 = pickle.load(open(filename_M1, 'rb'))\n",
    "result_M1 = loaded_model_M1.score(X_test, y_test)\n",
    "print(f\"âœ“ Model 1 loaded and verified\")\n",
    "print(f\"âœ“ Test score: {result_M1}\")\n",
    "\n",
    "# Use f1 score as well since accuracy may be insufficient for imbalanced classes\n",
    "# f1 = 2 * [(precision*recall)/(precision+recall)]\n",
    "# this way we can account for precision and recall as well as accuracy\n",
    "y_pred = loaded_model_M1.predict(X_test)\n",
    "modelF1Score = sklearn.metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"âœ“ F1score: {modelF1Score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09bee8",
   "metadata": {},
   "source": [
    "<h1>Model 1-2: Random Forest with Reduced (SelectKBest 20) Features</h1>\n",
    "  \n",
    "<b>Load and Fit Model with New Reduced Feature Set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier for Model 2 (Best Features)\n",
    "model_M2 = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Model 2 with full feature set...\")\n",
    "# Fit the model on training set\n",
    "model_M2.fit(X_NewTrain, y_NewTrain)\n",
    "print(\"âœ“ Model 2 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f827a3",
   "metadata": {},
   "source": [
    "<b>Save Fitted Model to Disk and Evaluate Model's Performance with accuracy and F1-Score</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model 2 to disk\n",
    "import sklearn\n",
    "filename_M2 = 'finalized_model_M1-2.sav'\n",
    "pickle.dump(model_M2, open(filename_M2, 'wb'))\n",
    "print(f\"âœ“ Model 2 saved as: {filename_M2}\")\n",
    "\n",
    "# Load the model from disk to verify\n",
    "loaded_model_M2 = pickle.load(open(filename_M2, 'rb'))\n",
    "result_M2 = loaded_model_M2.score(X_NewTest, y_NewTest)\n",
    "print(f\"âœ“ Model 2 loaded and verified\")\n",
    "print(f\"âœ“ Test score: {result_M2}\")\n",
    "\n",
    "# Use f1 score as well since accuracy may be insufficient for imbalanced classes\n",
    "# f1 = 2 * [(precision*recall)/(precision+recall)]\n",
    "# this way we can account for precision and recall as well as accuracy\n",
    "y_NewPred = loaded_model_M2.predict(X_NewTest)\n",
    "model2F1Score = sklearn.metrics.f1_score(y_NewTest, y_NewPred, average='weighted')\n",
    "print(f\"âœ“ F1score: {model2F1Score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
