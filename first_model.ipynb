{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8dadaa2",
   "metadata": {},
   "source": [
    "# ML Model Building - Submission\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading preprocessed data with NLP embeddings\n",
    "2. Feature selection to create a reduced feature set\n",
    "3. Building two models:\n",
    "   - **Model 1 (M1):** Full feature set\n",
    "   - **Model 2 (M2):** Reduced feature set (selected features only)\n",
    "4. Saving both models as `.sav` files for future use\n",
    "\n",
    "**Note:** This submission focuses on model building and saving. Performance evaluation will be included in the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d8b50",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")\n",
    "print(f\"âœ“ Random seed set to: 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f34ca",
   "metadata": {},
   "source": [
    "# Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c5b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed dataset with NLP embeddings\n",
    "df = pd.read_csv('data/processed/games_preprocessed.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Total samples: {df.shape[0]:,}\")\n",
    "print(f\"Total features (including target): {df.shape[1]}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3c91d",
   "metadata": {},
   "source": [
    "# Convert Embedding Strings to Numeric Arrays\n",
    "\n",
    "The 'About the game' column contains embedding vectors stored as strings. We need to convert them back to numeric arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5448465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Check if 'About the game' column exists and contains string representations of arrays\n",
    "if 'About the game' in df.columns:\n",
    "    print(\"Converting 'About the game' embeddings from strings to numeric arrays...\")\n",
    "    \n",
    "    # Convert string representations to actual arrays\n",
    "    def string_to_array(s):\n",
    "        if isinstance(s, str):\n",
    "            # Remove extra whitespace and convert to numpy array\n",
    "            return np.fromstring(s.strip('[]'), sep=' ')\n",
    "        return s\n",
    "    \n",
    "    df['About the game'] = df['About the game'].apply(string_to_array)\n",
    "    \n",
    "    print(f\"âœ“ Conversion complete!\")\n",
    "    print(f\"âœ“ Sample embedding shape: {df['About the game'].iloc[0].shape}\")\n",
    "    print(f\"âœ“ Sample embedding (first 10 values): {df['About the game'].iloc[0][:10]}\")\n",
    "else:\n",
    "    print(\"'About the game' column not found in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand embeddings into separate columns\n",
    "# This is necessary because sklearn models need 2D numeric arrays, not arrays within cells\n",
    "\n",
    "if 'About the game' in df.columns:\n",
    "    print(\"Expanding embeddings into separate columns...\")\n",
    "    \n",
    "    # Convert the 'About the game' column (which contains arrays) into separate columns\n",
    "    embeddings_list = df['About the game'].tolist()\n",
    "    embeddings_df = pd.DataFrame(embeddings_list, \n",
    "                                  columns=[f'embedding_{i}' for i in range(len(embeddings_list[0]))])\n",
    "    \n",
    "    # Drop the original 'About the game' column\n",
    "    df = df.drop('About the game', axis=1)\n",
    "    \n",
    "    # Insert embedding columns at the beginning\n",
    "    df = pd.concat([embeddings_df, df], axis=1)\n",
    "    \n",
    "    print(f\"âœ“ Expanded embeddings into {len(embeddings_list[0])} numeric columns\")\n",
    "    print(f\"âœ“ New dataset shape: {df.shape}\")\n",
    "    print(f\"âœ“ First few column names: {df.columns[:5].tolist()}\")\n",
    "    print(f\"âœ“ Last few column names: {df.columns[-5:].tolist()}\")\n",
    "else:\n",
    "    print(\"No embedding expansion needed - 'About the game' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable distribution\n",
    "print(\"Target variable distribution:\")\n",
    "print(df['popularity_class'].value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(df['popularity_class'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc93a1",
   "metadata": {},
   "source": [
    "# Prepare Data for Modeling\n",
    "\n",
    "Separate features (X) and target variable (y), then split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('popularity_class', axis=1)\n",
    "y = df['popularity_class']\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"\\nTotal number of features: {X.shape[1]}\")\n",
    "print(f\"\\nFeature data types:\")\n",
    "print(X.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b53f6",
   "metadata": {},
   "source": [
    "# Handle Non-Numeric Columns\n",
    "\n",
    "Check for and handle any remaining categorical/text columns that need to be encoded or removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc56ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-numeric columns in X\n",
    "print(\"Checking for non-numeric columns...\")\n",
    "print(f\"\\nData types in features:\")\n",
    "print(X.dtypes.value_counts())\n",
    "\n",
    "# Identify object (string) columns\n",
    "object_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if object_cols:\n",
    "    print(f\"\\nâš  Found {len(object_cols)} non-numeric columns:\")\n",
    "    for col in object_cols:\n",
    "        print(f\"  - {col}: {X[col].nunique()} unique values\")\n",
    "        print(f\"    Sample values: {X[col].dropna().head(3).tolist()}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Dropping non-numeric columns: {object_cols}\")\n",
    "    X = X.drop(columns=object_cols)\n",
    "    print(f\"âœ“ Remaining features: {X.shape[1]}\")\n",
    "else:\n",
    "    print(\"âœ“ All columns are numeric!\")\n",
    "\n",
    "print(f\"\\nFinal feature set shape: {X.shape}\")\n",
    "print(f\"Final feature types:\\n{X.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81985d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80/20 split)\n",
    "# Use stratify to maintain class distribution in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbbec3a",
   "metadata": {},
   "source": [
    "# Model 1: Random Forest with Full Feature Set\n",
    "\n",
    "Train a Random Forest Classifier using all available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier for Model 1 (Full Feature Set)\n",
    "model_M1 = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Model 1 with full feature set...\")\n",
    "# Fit the model on training set\n",
    "model_M1.fit(X_train, y_train)\n",
    "print(\"âœ“ Model 1 training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb11fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model 1 to disk\n",
    "filename_M1 = 'finalized_model_M1.sav'\n",
    "pickle.dump(model_M1, open(filename_M1, 'wb'))\n",
    "print(f\"âœ“ Model 1 saved as: {filename_M1}\")\n",
    "\n",
    "# Load the model from disk to verify\n",
    "loaded_model_M1 = pickle.load(open(filename_M1, 'rb'))\n",
    "result_M1 = loaded_model_M1.score(X_test, y_test)\n",
    "print(f\"âœ“ Model 1 loaded and verified\")\n",
    "print(f\"âœ“ Test score: {result_M1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d48d35",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Use SelectKBest with ANOVA F-statistic to select the most important features for Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e5dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "461a683b",
   "metadata": {},
   "source": [
    "# Model 2: Random Forest with Reduced Feature Set\n",
    "\n",
    "Train a Random Forest Classifier using only the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c9ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
